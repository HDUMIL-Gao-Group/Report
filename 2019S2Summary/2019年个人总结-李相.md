<!--
 * @Description: 
 * @Author: shaonianruntu
 * @Github: 
 * @Date: 2020-01-17 10:54:53
 * @LastEditTime : 2020-01-23 16:03:12
 -->
# 2019年个人总结-李相

<a href="https://github.com/HDUMIL-Gao-Group"><img src="https://img.shields.io/badge/Organization-%20Gao%20Group%20@%20HDUMIL-blue"></img></a>
<a href="https://github.com/Ausiden"><img src="https://img.shields.io/badge/Auther-李相-yellow"></img></a>
<img src="https://img.shields.io/badge/Grade-研一-ff85c0"></img>

- [2019年终总结](#2019%e5%b9%b4%e7%bb%88%e6%80%bb%e7%bb%93)
  - [目录](#%e7%9b%ae%e5%bd%95)
  - [这学期主要工作](#%e4%b8%8a%e5%8d%8a%e5%b9%b4%e5%b7%a5%e4%bd%9c)
    - [论文的实验](#%e8%ae%ba%e6%96%87%e7%9a%84%e5%ae%9e%e9%aa%8c)
      - [实验结果](#%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c)
  - [下学期准备做的事情](#%e4%b8%8b%e5%8d%8a%e5%b9%b4%e5%b7%a5%e4%bd%9c)

#### 这学期主要工作

在CUHK数据集上以pix2pix为baseline，加入APDrawingGan中的local网络以及超分辨率重建论文中的广义梯度损失

##### 数据预处理

在CUHK数据集用mtcnn实现人脸观测点检测，对于检测不到的人脸，在face++上进行检测，然后手动定位，效果图如下

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/1.png )

图像的mask是通过朱师姐的parsing跑的，效果如下:

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/2.jpg)



由于CUHK是200 * 250的图像,首先对图像进行填充至256 * 256，在训练的时候将他填充到286 * 286，测试时不变，此时baseline跑出来的fid是28左右，但是若测试时也是256 * 256，则跑出来的fid 是50多，可能是由于过拟合了，因为训练时填充286 * 286再随机裁剪到256 * 256,这个随机过程不容易导致过拟合

##### 损失函数

用了GAN损失，L1损失、Ggrad（广泛梯度损失）以及Local损失

##### 目前得到的结果

从左到右分别为

真实照片

真实的素描图像

baseline  : Gloss = CE_loss +lamb_L1 *  L1

baseline+glad : Gloss =CE_loss+lamb_L1 * L1 + lamb_glad * glad

baseline+local : Gloss = CE_loss + lamb_L1 * L1 + lamb_local * local

baseline+local+glad : Gloss = CE_loss + lamb_L1 * L1 +  lamb_glad * glad+lamb_local * local

得到的效果图：

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/3.jpg)

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/4.jpg)

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/5.jpg)

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/6.jpg)

实验的fid效果

baseline  : Gloss = CE_loss +lamb_L1 *  L1(100)

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/7.png)

平均fid:28.43

baseline+glad : Gloss =CE_loss+lamb_L1 * L1（100） + lamb_glad * glad（100）

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/8.png)

平均fid:28.00

baseline+local : Gloss = CE_loss + lamb_L1 * L1（100） + lamb_local * local（25）

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/9.png)

平均fid:30.88

baseline+local+glad : Gloss = CE_loss + lamb_L1 * L1（100） +  lamb_glad（100）* glad+lamb_local（25） * local

![](https://github.com/HDUMIL-Gao-Group/Report/blob/master/2019S2Summary/dln-assets/10.png)

平均fid:32.08

#### 下学期准备做的事情：

1.对于有些照片特别是XM2VTS0类型的照片容易照成分区域特别明显，可能是需要进一步调参，由于代码跑的比较慢，到目前为止还没有测出比较好的参数

2.对融合网络进行修改，看哪种效果比较好

3.区域生成存在的问题是照片x和画像y各个区域之间并没有精确对齐，训练时会引入误差。
方法：
1）学习 照片parsing Px 和画像parsing Py 之间的几何变形关系：Px = T(Py)。T应该是个坐标之间的变换。
2）然后，把变换关系T应用到对应的画像上，对画像进行校正：y' = T(y)。利用y'进行学习。

将这个操作可以用到整张人脸上，也可以考虑在各个区域单独使用。（参考时尚相关的论文）

目的是：找到一个不是通过训练的模型，而是给出 Px，Py 可以自动估计两者之间的坐标映射关系。

4.在寒假时需要对挑战杯的文本进行修改



